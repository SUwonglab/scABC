---
title: "pipeline_scABC_Lin"
author: "Zhixiang Lin"
date: "April 25, 2017"
output: pdf_document
---

```{r}
library(readr)
library(WeightedCluster)
```

The functions needed

```{r}
selectTop <- function(x, top){
  ## this function select top peaks in x and set the other elements to 0
  thres <- sort(x, decreasing=T)[top]
  x[x<thres] <- 0
  return(x)
}

getClusterSpecificPvalue <- function(data, cluster, offset, landmark=NULL, maxiter=1000, thresMLE=10^-3, thresMAP=10^-5, quiet=FALSE){
  ## the main function for peak selection
  ## data is nPeaks(p) by Cells(n)
  ## cluster is the cluster membership matrix, length n. Take entries 1 to nCluster
  ## offset corresponds to h_i, here it is a vector of length n
  ## landmark is optional. If landmark is provided, we only do hypothesis testing on the union of landmark peaks
  if (!is.null(landmark)){
    ## take union of the landmark peaks
    unionlandmark <- which(rowSums(landmark)!=0)
    p <- nrow(data)
    data <- data[unionlandmark,]
  } else {
  }
  
  data <- t(data) # make data n by p
  
  ## get beta_MLE
  if (!quiet){
    cat("\nEstimating beta MLE\n")  
  }
  betaMLE_ini <- matrix(0, nrow=length(unique(cluster)), ncol=ncol(data))
  betaMLE <- getbetaMLE(data=data, cluster=cluster, offset=offset, beta_ini=betaMLE_ini, maxiter=maxiter, thres=thresMLE, quiet=quiet)
  
  ## get the empirical prior sigma
  sigmas <- getSigmaPrior(betaMLE)
  
  ## get beta_MAP and the p-value
  if (!quiet){
    cat("\nEstimating beta MAP\n")
  }
  betaMAP_ini <- rbind(0, matrix(0, nrow=length(unique(cluster)), ncol=ncol(data)))
  result <- getbetaMAP(data=data, cluster=cluster, offset=offset, sigmas=sigmas, beta_ini=betaMAP_ini, maxiter=maxiter, thres=thresMAP, quiet=quiet)
  
  if (!is.null(landmark)){
    betaMAP <- matrix( nrow=length(unique(cluster))+1, ncol=p )
    pvalue <- matrix( nrow=p, ncol=length(unique(cluster)) )
    betaMAP[, unionlandmark] <- result$beta
    pvalue[unionlandmark,] <- result$pvalue
  } else {
    betaMAP <- result$beta
    pvalue <- result$pvalue
  }
  colnames(pvalue) <- paste("Cluster", 1:length(unique(cluster)) )
  return(list(betaMAP=betaMAP, sigmas=sigmas, pvalue=pvalue))
}

getbetaMLE <- function(data, cluster, offset, beta_ini, maxiter, thres, quiet){
  ## data is n by p
  ## cluster is the cluster membership matrix, length n. Take entries 1 to nCluster
  ## offset corresponds to h_i, here it is a vector of length n
  p <- ncol(data)
  x <- getdesign(cluster)
  beta <- beta_ini
  betaDiffs <- c() 
  percConverged <- c()
  converged_flag <- rep(0, p)
  
  converged <- 0
  iter <- 1
  while (!converged & iter<maxiter){
    mu <- offset*exp(x%*%beta) 
    u <- crossprod(x, data-mu)
    updateBeta <- function(r){
      if (converged_flag[r]==0 & !is.na(beta[1,r]) ){
        Jr <- crossprod(x, mu[,r]*x)
        betaDiff <- try(solve(Jr, u[,r]), silent=T)
        if (class(betaDiff)=="try-error"){
          return( rep(NA, length(beta[,r])) )    
        } else {
          return(beta[,r] + betaDiff)  
        }
      } else {
        return(beta[,r])
      }
    }
    
    betaPre <- beta
    beta <- sapply(1:p, updateBeta)
    betaDiffs <- rbind(betaDiffs, colSums(abs(beta - betaPre)) )
    converged_flag <- (betaDiffs[iter,] <= thres) + 0
    converged_flag[which(is.na(converged_flag))] <- 0
    singular_flag <- is.na(beta[1,]) + 0
    percConverged <- c(percConverged, sum(converged_flag[which(singular_flag==0)])/sum(singular_flag==0) )
    
    if (!quiet){
        cat("\r", round(percConverged[length(percConverged)]*100), "%", "converged")  
    }
    if (percConverged[length(percConverged)]==1){
      converged <- 1
    }
    iter <- iter + 1
  }
  return(beta)
}

getdesign <- function(cluster){
  nCluster <- length(unique(cluster))
  n <- length(cluster)
  x <- matrix(0, nrow=n, ncol=nCluster)
  for (i in 1:nCluster){
    x[which(cluster==i), i] <- 1
  }
  return(x)
}

getSigmaPrior <- function(beta, q=0.05){
  ## get the empirical prior estimate
  ## q is the quantile to match
  
  ## center each column in beta
  betaC <- t(t(beta) - colMeans(beta))
  ## 
  sigmas <- rep(0, nrow(betaC))
  for (i in 1:nrow(betaC)){
    tmp <- betaC[i,]
    tmp <- tmp[which(!is.na(tmp))]
    sigmas[i] <- quantile(abs(tmp), 1-q)/qnorm(1-q/2)
  }
  return(sigmas)
}

getbetaMAP <- function(data, cluster, offset, sigmas, beta_ini, maxiter, thres, quiet){
  ## data is n by p
  ## beta_ini includes the intercept
  ## cluster is the cluster membership matrix, length n. Take entries 1 to nCluster
  ## offset corresponds to h_i, here it is a vector of length n
  
  p <- ncol(data)
  x <- getdesign(cluster)
  ## add the intercept in x
  x <- cbind(1, x)
  ## get lambda
  lambda <- c(0, 1/sigmas^2)
  
  beta <- beta_ini
  betaDiffs <- c()
  percConverged <- c()
  converged_flag <- rep(0, p)
  
  converged <- 0
  iter <- 1
  while (!converged & iter<maxiter){
    mu <- offset*exp(x%*%beta) 
    z <- log(mu/offset) + (data-mu)/mu
    
    updateBetaRidge <- function(r){
      if (converged_flag[r]==0){
        JrRidge <- crossprod(x, mu[,r]*x) + diag(lambda)
        betar <- solve(JrRidge, crossprod(x, matrix(mu[,r]*z[,r], ncol=1)) )
        return( as.vector(betar) )
      } else {
        return(beta[,r])
      }
    }
    
    betaPre <- beta
    beta <- sapply(1:p, updateBetaRidge)
    betaDiffs <- rbind(betaDiffs, colSums(abs(beta - betaPre)) )
    converged_flag <- (betaDiffs[iter,] <= thres) + 0
    percConverged <- c(percConverged, sum(converged_flag)/p )
    
    if (!quiet){
        cat("\r", round(percConverged[length(percConverged)]*100), "%", "converged")  
    }
    
    if (percConverged[length(percConverged)]==1){
      converged <- 1
    }
    iter <- iter + 1
  }
  mu <- offset*exp(x%*%beta) 
  
  ## get all the contrast matrices and cluster label for each contrast
  nCluster <- length(unique(cluster))
  tmp <- getContrast(nCluster)
  constrasts <- tmp$constrasts
  
  ## pad the intercept with 0 in the constrast
  constrasts <- cbind(0, constrasts)
  constrastsCluster <- tmp$constrastsCluster
  
  calRidgePvalueA <- function(r){
    ## calculates the p-value for a small hypothesis
    if ( !is.na(beta[1,r]) ){
      Jr <- crossprod(x, mu[,r]*x)
      JrRidgeInv <- solve(Jr + diag(lambda))
      covRidge <- JrRidgeInv%*%Jr%*%JrRidgeInv
      ##
      betaC <- constrasts%*%matrix(beta[,r], ncol=1)  
      CcovC <- constrasts%*%covRidge%*%t(constrasts)
      SEbetaC <- sqrt(diag(CcovC))
      ##
      pvs <- pnorm(betaC/SEbetaC, lower.tail = FALSE)
      return(pvs)
    } else {
      return(rep(NA, length(constrastsCluster)))
    }
  }
  if (!quiet){
    cat("\nCalculating the p-values\n")
  }
  pvsA <- sapply(1:p, calRidgePvalueA) 
  ## get the p-value for the large null hypothesis by taking maximum
  if (nCluster>2){
    pvs <- c()
    for (i in 1:nCluster){
      pvs <- cbind(pvs, apply(pvsA[which(constrastsCluster==i),], 2, max))
    }  
  } else {
    pvs <- t(pvsA)
  }
  return(list(beta=beta, pvalue=pvs))
}

getContrast <- function(nCluster){
  ## get all the contrasts that is needed to calculate the p-value
  constrasts <- matrix(0, nrow=(nCluster-1)*nCluster, ncol=nCluster)
  constrastsCluster <- rep(1:nCluster, each=nCluster-1)
  for (i in 1:nCluster){
    constrasttmp <- matrix(0, nrow=nCluster-1, ncol=nCluster)
    constrasttmp[, i] <- 1
    count <- 1
    for (j in 1:(nCluster-1)){
      constrasttmp[count, (c(1:nCluster)[-i])[j]] <- -1
      count <- count + 1
    }
    constrasts[(i*(nCluster-1)-(nCluster-1)+1):(i*(nCluster-1)), ] <- constrasttmp
  }
  return(list(constrasts=constrasts, constrastsCluster=constrastsCluster))
}
```

## input

Load the data. $ForeGround$ and $BackGround$ are $region \times num of samples$.   

```{r}
#setwd("")
ForeGround <- read_csv("C:/Users/Zhixiang/Data/CellLines6/SelectedPeaksLargeSub/ForeGround.csv", col_names = FALSE)
ForeGround <- as.matrix(ForeGround)

BackGround <- read_csv("C:/Users/Zhixiang/Data/CellLines6/SelectedPeaksLargeSub/BackGround.csv", col_names = FALSE)
BackGround <- as.matrix(BackGround)
```

## run scABC unsupervised clustering

Calculate 1 - Spearman 

```{r}
distS <- 1-cor(ForeGround, method="spearman")
```

Calculate the median of BackGround for each sample

```{r}
BackGroundMedian <- apply(BackGround, 2, median)
```

Step 1, weighted K-medoids clustering. Use the sigmoid function $\frac{1}{1+\exp^{-(BackGroundMedian-c)/(\lambda*c)}}$ to calculate the weight. $\lambda$ and $c$ are two tuning parameters. By default $c=quantile(BackGroundMedian, 0.5)$ and $\lambda=0.1$. 

```{r}
## parameters
nCluster <- 6
lambda <- 0.1
c <- quantile(BackGroundMedian, 0.5)
##
W <- 1/(1+exp(-(BackGroundMedian-c)/(c*lambda)))
result <- wcKMedoids(distS, k=nCluster, weights=W)
clusterStep1 <- result$clustering
clusterStep1 <- as.numeric(factor(clusterStep1))
```

Step 2, get the landmark.
$landmark$ is $num of peaks \times num of lanmarks$

```{r}
landmarks <- c()
for (i in 1:nCluster){
  tmp <- which(clusterStep1==i)
  if (length(tmp)==1){
        landmarks <- cbind(landmarks, ForeGround[,tmp]  )  
  } else {
        landmarks <- cbind(landmarks, rowSums(ForeGround[,tmp])  ) 
  }
}
top <- 2000
landmarksTop <- apply(landmarks, 2, selectTop, top)
```

Step 3, refine the clustering result with the landmark.

```{r}
unionTopPeak <- which(rowSums(landmarksTop)>0)
scorU <- cor(ForeGround[unionTopPeak,], landmarksTop[unionTopPeak,], method="spearman")
clusterStep3 <- apply(scorU, 1, which.max) 
```

## run scABC to select cluster specific peaks

```{r}
resultPeakSelection <- getClusterSpecificPvalue(data=ForeGround, cluster=clusterStep3, offset=BackGroundMedian, landmark=landmarksTop)
## output:
## beta_MAP
## empirical prior sigma
## cluster specific p-values. Each column correspond to a cluster
## the NA values in beta_MAP and pvalue represent the non-landmark peaks, which is not tested if landmark is provided.
```
